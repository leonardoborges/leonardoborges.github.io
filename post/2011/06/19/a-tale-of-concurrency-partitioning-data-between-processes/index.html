<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Leonardo Borges </title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.67.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="" />
<meta property="og:description" content="So I had just finished writing this feature. I was confident it&rsquo;d work - after all I had a good level of tests around it. It sounded like yet another successful deployment.
One week in and something starts breaking. It was hard to track down but at the end I realised it was caused by having concurrent processes running in parallel.
That&rsquo;s what happened in a recent production release at our current client." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://leonardoborges.com/post/2011/06/19/a-tale-of-concurrency-partitioning-data-between-processes/" />
<meta property="article:published_time" content="2011-06-19T00:00:00+00:00" />
<meta property="article:modified_time" content="2011-06-19T00:00:00+00:00" />
<meta itemprop="name" content="">
<meta itemprop="description" content="So I had just finished writing this feature. I was confident it&rsquo;d work - after all I had a good level of tests around it. It sounded like yet another successful deployment.
One week in and something starts breaking. It was hard to track down but at the end I realised it was caused by having concurrent processes running in parallel.
That&rsquo;s what happened in a recent production release at our current client.">
<meta itemprop="datePublished" content="2011-06-19T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2011-06-19T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1139">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="So I had just finished writing this feature. I was confident it&rsquo;d work - after all I had a good level of tests around it. It sounded like yet another successful deployment.
One week in and something starts breaking. It was hard to track down but at the end I realised it was caused by having concurrent processes running in parallel.
That&rsquo;s what happened in a recent production release at our current client."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="http://leonardoborges.com/" class="f3 fw2 hover-white no-underline white-90 dib">
      Leonardo Borges
    </a>
    <div class="flex-l items-center">
      

      
      














    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=http://leonardoborges.com/post/2011/06/19/a-tale-of-concurrency-partitioning-data-between-processes/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=http://leonardoborges.com/post/2011/06/19/a-tale-of-concurrency-partitioning-data-between-processes/&amp;text=" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://leonardoborges.com/post/2011/06/19/a-tale-of-concurrency-partitioning-data-between-processes/&amp;title=" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>

      <h1 class="f1 athelas mt3 mb1"></h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2011-06-19T00:00:00Z">June 19, 2011</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>So I had just finished writing this feature. I was confident it&rsquo;d work - after all I had a good level of tests around it.
It sounded like yet another successful deployment.</p>
<p>One week in and something starts breaking. It was hard to track down but at the end I realised it was caused by having concurrent processes running in parallel.</p>
<p>That&rsquo;s what happened in a recent production release at our current client. It was a very interesting problem to track
down and solve and I&rsquo;ll do my best to explain and walk you through it here.</p>
<h2 id="what-we-were-trying-to-achieve-">What we were trying to achieve</h2>
<p>I&rsquo;ll try not to go into many details here as to how the feature works but here is the gist of it:</p>
<p>A user from the staff can select from a range of criteria to create a &ldquo;List&rdquo; that is used to match users against the database.
These criteria are serialized to the database in this list object to allow for further processing.</p>
<p>When required, the staff can choose to mail the users resulting from that list. To get the set of users, the system
de-serializes the criteria contained in the list, builds a SQL query and runs it against the database.</p>
<h2 id="constraints-">Constraints</h2>
<p>These lists are contained in something called a &ldquo;Push&rdquo;. That&rsquo;s just a concept that identifies that a set of lists and
emails belong to a specific theme, say, &lsquo;Kitty lovers&rsquo;.</p>
<p>It&rsquo;s a powerful concept though because its single most important rule is that a user should <strong>never</strong> receive more than one email within the same &ldquo;Push&rdquo;.</p>
<p>For example, take a look at the image below, which represents a Push in progress. Let <strong>U</strong> be the universe of all users in the database. <strong>L</strong> are users returned by a List within a given Push. <strong>R</strong> is the set of users that have already received an email from that Push.</p>
<p>{{< figure src="/images/p>" >}}<p>Based on the rules I explained above, the green area then represents users we can still send emails to.</p>
<h2 id="content-testing-">Content testing</h2>
<p>With all the basic concepts in place, let&rsquo;s pretend we are actually creating a Push for the &lsquo;Kitty Lovers&rsquo;. I am organizing
a kitty expo at my house and I want to invite everyone that lives within 50km of Sydney, Australia - see the list specification going on here?</p>
<p>Let&rsquo;s say this list gives us 25000 users. My house&rsquo;s better be huge.</p>
<p>Simple enough, but I actually have 2 emails to send. They have different content, say 2 different pictures, and before
I invite everyone, I want to test which email works best by sending them both to a subset of the list - make it a thousand random users each.
After all, I want my event to be a huge success.</p>
<p>After I decide which email is best - the system tracks opens, clicks, etc&hellip; - I want to send it to the rest of the list,
which is to say every user that has not received an email from this Push yet.</p>
<h2 id="offloading-work-the-problem-begins-">Offloading work, the problem begins</h2>
<p>Due to certain architecture and performance requirements the unit of code that runs the list&rsquo;s criteria against the database,
gets the user ids and sends the email, is sent to a job queue to be later executed by a background process.</p>
<p>In development and staging we only ever had a single background process running so all was well. The code was basically executed sequentially.</p>
<p>In production however, we can - and usually have - several background workers picking up jobs from the queue. And that&rsquo;s when the bug happened:</p>
<p>{{< figure src="/images/p>" >}}<p>As you can see in the above image, given you have 2 jobs running in parallel, Job#1 selects the users from the list, starts sending some emails and in the meantime
Job#2 comes along, selects roughly the same users and starts doing the same before Job#1 has had enough time to mark
those users as having received the email already. Bam! Some users will receive duplicates!</p>
<h2 id="the-solution-">The solution</h2>
<p>I spent a lot of time literally staring at my laptop&rsquo;s screen thinking about how to solve this issue. Locking the table?
Nah&hellip; that would render having multiple workers useless.</p>
<p>What I really needed was a way to partition the data between jobs so as to avoid different jobs from dealing with the same set of users.</p>
<p>My next thought was to run the query once beforehand to sort the list of user ids, split it in groups equal to the number of jobs
and work out the id ranges each job should deal with.</p>
<p>Although this solution would work, it would add the extra step of running the query once before actually running the jobs.
That did not make me happy.</p>
<p>That&rsquo;s when I started thinking about a metaphor that helped me come up with this insight: a Hash Table. If you ever implemented
one you can see that the buckets in a hash table could be related to the jobs we have running.</p>
<p>I basically wanted different users to go to different buckets. Think hash functions. Think modulus.</p>
<p>To follow this approach I changed my code so that each job would be assigned an id, starting at 0, up to (number_of_jobs - 1).
Then, when putting the jobs in the queue I would provide 2 extra arguments:
<strong>the current job id</strong> and <strong>the total number of jobs</strong>.</p>
<p>Upon execution, the job would use these extra arguments to modify the query, adding an extra field to the select clause:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql">        <span style="color:#66d9ef">SELECT</span> ..., <span style="color:#66d9ef">MOD</span>(users.id, number_of_jobs) <span style="color:#66d9ef">AS</span> modulus...
</code></pre></div><p>And it would also append an extra filter to the where clause:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql">        <span style="color:#66d9ef">WHERE</span> ... <span style="color:#66d9ef">AND</span> modulus <span style="color:#f92672">=</span> current_job_id
</code></pre></div><p>That way, users would be spread as evenly as possible between jobs and no single user would be processed by more than one job.</p>
<p>For example: If we had 2 jobs, ids 0 and 1 and a list of 10 users with ids from 0 to 10, this would be the users distribution between jobs:</p>
<pre><code>      user_id:0 - processed by job_id:0 (given by 0 mod 2)
      user_id:1 - processed by job_id:1 (given by 1 mod 2)
      user_id:2 - processed by job_id:0 (given by 2 mod 2)
      user_id:3 - processed by job_id:1 (given by 3 mod 2)
      user_id:4 - processed by job_id:0 (given by 4 mod 2)
      user_id:5 - processed by job_id:1 (given by 5 mod 2)
      user_id:6 - processed by job_id:0 (given by 6 mod 2)
      user_id:7 - processed by job_id:1 (given by 7 mod 2)
      user_id:8 - processed by job_id:0 (given by 8 mod 2)
      user_id:9 - processed by job_id:1 (given by 9 mod 2)
      user_id:10 - processed by job_id:0 (given by 10 mod 2)
</code></pre><p>A simple, elegant solution for a tricky problem. One that I&rsquo;m finally happy about.</p>
<p>If you made it to here, I appreciate your patience and hope you enjoyed the read ;)</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "leonardoborges" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://leonardoborges.com/" >
    &copy;  Leonardo Borges 2020 
  </a>
    <div>













</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
